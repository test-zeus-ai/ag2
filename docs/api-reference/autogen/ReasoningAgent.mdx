---
sidebarTitle: ReasoningAgent
title: autogen.ReasoningAgent
---
<h2 id="autogen.ReasoningAgent" class="doc doc-heading">
    <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>
    <span class="doc doc-object-name doc-class-name">ReasoningAgent</span>
</h2>

```python
ReasoningAgent(
    name: str,
    llm_config: dict,
    grader_llm_config: dict | None = None,
    max_depth: int = 4,
    beam_size: int = 3,
    answer_approach: str = 'pool',
    verbose: bool = True,
    reason_config: dict = \{},
    **kwargs
)
```

    (In preview) Assistant agent, designed to solve a task with LLM.
    
    AssistantAgent is a subclass of ConversableAgent configured with a default system message.
    The default system message is designed to solve a task with LLM,
    including suggesting python code blocks and debugging.
    `human_input_mode` is default to "NEVER"
    and `code_execution_config` is default to False.
    This agent doesn't execute code by default, and expects the user to execute the code.
    
    Initialize a ReasoningAgent that uses tree-of-thought reasoning.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `name` | Name of the agent<br/><br/>**Type:** `str` |
| `llm_config` | Configuration for the language model<br/><br/>**Type:** `dict` |
| `grader_llm_config` | Optional separate configuration for the grader model.<br/><br/>If not provided, uses llm_config<br/><br/>**Type:** `dict \| None`<br/><br/>**Default:** None |
| `max_depth` | Maximum depth of the reasoning tree<br/><br/>**Type:** `int`<br/><br/>**Default:** 4 |
| `beam_size` | DEPRECATED.<br/><br/>Number of parallel reasoning paths to maintain<br/><br/>**Type:** `int`<br/><br/>**Default:** 3 |
| `answer_approach` | DEPRECATED.<br/><br/>Either "pool" or "best" - how to generate final answer<br/><br/>**Type:** `str`<br/><br/>**Default:** 'pool' |
| `verbose` | Whether to show intermediate steps<br/><br/>**Type:** `bool`<br/><br/>**Default:** True |
| `reason_config` | Configuration for the reasoning method.<br/><br/>Supported parameters: method (str): The search strategy to use.<br/><br/>Options: - "beam_search" (default): Uses beam search with parallel paths - "mcts": Uses Monte Carlo Tree Search for exploration - "lats": Uses Language Agent Tree Search with per-step rewards - "dfs": Uses depth-first search (equivalent to beam_search with beam_size=1) Common parameters: max_depth (int): Maximum depth of reasoning tree (default: 3) forest_size (int): Number of independent trees to maintain (default: 1) rating_scale (int): Scale for grading responses, e.g.<br/><br/>1-10 (default: 10) Beam Search specific: beam_size (int): Number of parallel paths to maintain (default: 3) answer_approach (str): How to select final answer, "pool" or "best" (default: "pool") MCTS/LATS specific: nsim (int): Number of simulations to run (default: 3) exploration_constant (float): UCT exploration parameter (default: 1.41) Example configs: `\\{"method": "beam_search", "beam_size": 5, "max_depth": 4}` `\\{"method": "mcts", "nsim": 10, "exploration_constant": 2.0}` `\\{"method": "lats", "nsim": 5, "forest_size": 3}`<br/><br/>**Type:** `dict`<br/><br/>**Default:** \{} |
| `**kwargs` |  |

### Instance Attributes

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### method
<br />

    <br />

### Instance Methods

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### generate_forest_response

```python
generate_forest_response(
    self,
    messages: list[dict],
    sender: autogen.Agent,
    config: dict | None = None
) -> tuple[bool, str]
```

    Generate a response using tree-of-thought reasoning.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `messages` | Input messages to respond to<br/><br/>**Type:** `list[dict]` |
| `sender` | Agent sending the messages<br/><br/>**Type:** `autogen.Agent` |
| `config` | Optional configuration<br/><br/>**Type:** `dict \| None`<br/><br/>**Default:** None |

<b>Returns:</b>
| Type | Description |
|--|--|
| `tuple[bool, str]` | Tuple[bool, str]: Success flag and generated response |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### rate_node

```python
rate_node(
    self,
    node: autogen.ThinkNode,
    ground_truth: str = None,
    is_outcome: bool = False
) -> float
```

    Rate the quality of a reasoning path using the grader agent.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `node` | Node containing the reasoning trajectory to evaluate<br/><br/>**Type:** `autogen.ThinkNode` |
| `ground_truth` | Optional ground truth to provide to the grader<br/><br/>**Type:** `str`<br/><br/>**Default:** None |
| `is_outcome` | indicates whether the rating is for an outcome (final answer) or a process (thinking trajectory).<br/><br/>**Type:** `bool`<br/><br/>**Default:** False |

<b>Returns:</b>
| Type | Description |
|--|--|
| `float` | float: Normalized score between 0 and 1 indicating trajectory quality |

<br />