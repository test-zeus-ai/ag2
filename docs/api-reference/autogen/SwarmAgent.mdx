---
sidebarTitle: SwarmAgent
title: autogen.SwarmAgent
---
<h2 id="autogen.SwarmAgent" class="doc doc-heading">
    <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>
    <span class="doc doc-object-name doc-class-name">SwarmAgent</span>
</h2>

```python
SwarmAgent(
    name: str,
    system_message: str | None = 'You are a helpful AI Assistant.',
    llm_config: dict | Literal[False] | None = None,
    functions: list[typing.Callable] | Callable = None,
    is_termination_msg: Callable[[dict], bool] | None = None,
    max_consecutive_auto_reply: int | None = None,
    human_input_mode: Literal['ALWAYS', 'NEVER', 'TERMINATE'] = 'NEVER',
    description: str | None = None,
    code_execution_config=False,
    update_agent_state_before_reply: list[Callable | autogen.UPDATE_SYSTEM_MESSAGE] | Callable | autogen.UPDATE_SYSTEM_MESSAGE | None = None,
    **kwargs
)
```

    Swarm agent for participating in a swarm.
    
    SwarmAgent is a subclass of ConversableAgent.
    
    Additional args:
        functions (List[Callable]): A list of functions to register with the agent.
        update_agent_state_before_reply (List[Callable]): A list of functions, including UPDATE_SYSTEM_MESSAGEs, called to update the agent before it replies.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `name` | name of the agent.<br/><br/>**Type:** `str` |
| `system_message` | system message for the ChatCompletion inference.<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** 'You are a helpful AI Assistant.' |
| `llm_config` | llm inference configuration.<br/><br/>Please refer to [OpenAIWrapper.create](/reference/autogen/OpenAIWrapper#create) for available options.<br/><br/>When using OpenAI or Azure OpenAI endpoints, please specify a non-empty 'model' either in `llm_config` or in each config of 'config_list' in `llm_config`.<br/><br/>To disable llm-based auto reply, set to False.<br/><br/>When set to None, will use self.DEFAULT_CONFIG, which defaults to False.<br/><br/>**Type:** `dict \| Literal[False] \| None`<br/><br/>**Default:** None |
| `functions` | **Type:** `list[typing.Callable] \| Callable`<br/><br/>**Default:** None |
| `is_termination_msg` | a function that takes a message in the form of a dictionary and returns a boolean value indicating if this received message is a termination message.<br/><br/>The dict can contain the following keys: "content", "role", "name", "function_call".<br/><br/>**Type:** `Callable[[dict], bool] \| None`<br/><br/>**Default:** None |
| `max_consecutive_auto_reply` | the maximum number of consecutive auto replies.<br/><br/>default to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).<br/><br/>When set to 0, no auto reply will be generated.<br/><br/>**Type:** `int \| None`<br/><br/>**Default:** None |
| `human_input_mode` | whether to ask for human inputs every time a message is received.<br/><br/>Possible values are "ALWAYS", "TERMINATE", "NEVER".<br/><br/>(1) When "ALWAYS", the agent prompts for human input every time a message is received.<br/><br/>Under this mode, the conversation stops when the human input is "exit", or when is_termination_msg is True and there is no human input.<br/><br/>(2) When "TERMINATE", the agent only prompts for human input only when a termination message is received or the number of auto reply reaches the max_consecutive_auto_reply.<br/><br/>(3) When "NEVER", the agent will never prompt for human input.<br/><br/>Under this mode, the conversation stops when the number of auto reply reaches the max_consecutive_auto_reply or when is_termination_msg is True.<br/><br/>**Type:** `Literal['ALWAYS', 'NEVER', 'TERMINATE']`<br/><br/>**Default:** 'NEVER' |
| `description` | a short description of the agent.<br/><br/>This description is used by other agents (e.g.<br/><br/>the GroupChatManager) to decide when to call upon this agent.<br/><br/>(Default: system_message)<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** None |
| `code_execution_config=False` |  |
| `update_agent_state_before_reply` | **Type:** `list[Callable \| autogen.UPDATE_SYSTEM_MESSAGE] \| Callable \| autogen.UPDATE_SYSTEM_MESSAGE \| None`<br/><br/>**Default:** None |
| `**kwargs` |  |

### Static Methods

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### process_nested_chat_carryover

```python
process_nested_chat_carryover(
    chat: dict[str, typing.Any],
    recipient: autogen.ConversableAgent,
    messages: list[dict[str, typing.Any]],
    sender: autogen.ConversableAgent,
    config: Any,
    trim_n_messages: int = 0
) -> None
```

    Process carryover messages for a nested chat (typically for the first chat of a swarm)
    
    The carryover_config key is a dictionary containing:
        "summary_method": The method to use to summarise the messages, can be "all", "last_msg", "reflection_with_llm" or a Callable
        "summary_args": Optional arguments for the summary method
    
    Supported carryover 'summary_methods' are:
        "all" - all messages will be incorporated
        "last_msg" - the last message will be incorporated
        "reflection_with_llm" - an llm will summarise all the messages and the summary will be incorporated as a single message
        Callable - a callable with the signature: my_method(agent: ConversableAgent, messages: List[Dict[str, Any]]) -> str

<b>Parameters:</b>
| Name | Description |
|--|--|
| `chat` | The chat dictionary containing the carryover configuration<br/><br/>**Type:** `dict[str, typing.Any]` |
| `recipient` | The recipient agent<br/><br/>**Type:** `autogen.ConversableAgent` |
| `messages` | The messages from the parent chat<br/><br/>**Type:** `list[dict[str, typing.Any]]` |
| `sender` | The sender agent<br/><br/>**Type:** `autogen.ConversableAgent` |
| `config` | **Type:** `Any` |
| `trim_n_messages` | The number of latest messages to trim from the messages list<br/><br/>**Type:** `int`<br/><br/>**Default:** 0 |

<br />

### Instance Methods

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### add_functions

```python
add_functions(self, func_list: list[typing.Callable]) -> 
```

    

<b>Parameters:</b>
| Name | Description |
|--|--|
| `func_list` | **Type:** `list[typing.Callable]` |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### add_single_function

```python
add_single_function(
    self,
    func: Callable,
    name=None,
    description=''
) -> 
```

    Add a single function to the agent, removing context variables for LLM use

<b>Parameters:</b>
| Name | Description |
|--|--|
| `func` | **Type:** `Callable` |
| `name=None` |  |
| `description=''` |  |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### generate_swarm_tool_reply

```python
generate_swarm_tool_reply(
    self,
    messages: list[dict] | None = None,
    sender: autogen.Agent | None = None,
    config: autogen.OpenAIWrapper | None = None
) -> tuple[bool, dict]
```

    Pre-processes and generates tool call replies.
    
    This function:
    1. Adds context_variables back to the tool call for the function, if necessary.
    2. Generates the tool calls reply.
    3. Updates context_variables and next_agent based on the tool call response.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `messages` | **Type:** `list[dict] \| None`<br/><br/>**Default:** None |
| `sender` | **Type:** `autogen.Agent \| None`<br/><br/>**Default:** None |
| `config` | **Type:** `autogen.OpenAIWrapper \| None`<br/><br/>**Default:** None |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### register_hand_off

```python
register_hand_off(self, hand_to: list[autogen.ON_CONDITION | autogen.AFTER_WORK] | autogen.ON_CONDITION | autogen.AFTER_WORK) -> 
```

    Register a function to hand off to another agent.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `hand_to` | A list of ON_CONDITIONs and an, optional, AFTER_WORK condition<br/><br/>**Type:** `list[autogen.ON_CONDITION \| autogen.AFTER_WORK] \| autogen.ON_CONDITION \| autogen.AFTER_WORK` |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### register_update_agent_state_before_reply

```python
register_update_agent_state_before_reply(self, functions: list[typing.Callable] | Callable | None) -> 
```

    Register functions that will be called when the agent is selected and before it speaks.
    You can add your own validation or precondition functions here.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `functions` | A list of functions to be registered.<br/><br/>Each function is called when the agent is selected and before it speaks.<br/><br/>**Type:** `list[typing.Callable] \| Callable \| None` |

<br />