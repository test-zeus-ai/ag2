---
sidebarTitle: AgentBuilder
title: autogen.agentchat.contrib.captainagent.AgentBuilder
---
<h2 id="autogen.agentchat.contrib.captainagent.AgentBuilder" class="doc doc-heading">
    <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>
    <span class="doc doc-object-name doc-class-name">AgentBuilder</span>
</h2>

```python
AgentBuilder(
    config_file_or_env: str | None = 'OAI_CONFIG_LIST',
    config_file_location: str | None = '',
    builder_model: str | list | None = [],
    agent_model: str | list | None = [],
    builder_model_tags: list | None = [],
    agent_model_tags: list | None = [],
    max_agents: int | None = 5
)
```

    AgentBuilder can help user build an automatic task solving process powered by multi-agent system.
    Specifically, our building pipeline includes initialize and build.
    
    (These APIs are experimental and may change in the future.)

<b>Parameters:</b>
| Name | Description |
|--|--|
| `config_file_or_env` | path or environment of the OpenAI api configs.<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** 'OAI_CONFIG_LIST' |
| `config_file_location` | **Type:** `str \| None`<br/><br/>**Default:** '' |
| `builder_model` | specify a model as the backbone of build manager.<br/><br/>**Type:** `str \| list \| None`<br/><br/>**Default:** [] |
| `agent_model` | specify a model as the backbone of participant agents.<br/><br/>**Type:** `str \| list \| None`<br/><br/>**Default:** [] |
| `builder_model_tags` | **Type:** `list \| None`<br/><br/>**Default:** [] |
| `agent_model_tags` | **Type:** `list \| None`<br/><br/>**Default:** [] |
| `max_agents` | max agents for each task.<br/><br/>**Type:** `int \| None`<br/><br/>**Default:** 5 |

### Class Attributes

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### AGENT_DESCRIPTION_PROMPT
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### AGENT_NAME_PROMPT
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### AGENT_SEARCHING_PROMPT
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### AGENT_SELECTION_PROMPT
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### AGENT_SYS_MSG_PROMPT
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### CODING_AND_TASK_SKILL_INSTRUCTION
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### CODING_PROMPT
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### DEFAULT_DESCRIPTION
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### DEFAULT_PROXY_AUTO_REPLY
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### GROUP_CHAT_DESCRIPTION
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### online_server_name
<br />

    <br />

### Instance Methods

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### build

```python
build(
    self,
    building_task: str,
    default_llm_config: dict,
    coding: bool | None = None,
    code_execution_config: dict | None = None,
    use_oai_assistant: bool | None = False,
    user_proxy: autogen.ConversableAgent | None = None,
    max_agents: int | None = None,
    **kwargs
) -> tuple[list[autogen.ConversableAgent], dict]
```

    Auto build agents based on the building task.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `building_task` | instruction that helps build manager (gpt-4) to decide what agent should be built.<br/><br/>**Type:** `str` |
| `default_llm_config` | specific configs for LLM (e.g., config_list, seed, temperature, ...).<br/><br/>**Type:** `dict` |
| `coding` | use to identify if the user proxy (a code interpreter) should be added.<br/><br/>**Type:** `bool \| None`<br/><br/>**Default:** None |
| `code_execution_config` | specific configs for user proxy (e.g., last_n_messages, work_dir, ...).<br/><br/>**Type:** `dict \| None`<br/><br/>**Default:** None |
| `use_oai_assistant` | use OpenAI assistant api instead of self-constructed agent.<br/><br/>**Type:** `bool \| None`<br/><br/>**Default:** False |
| `user_proxy` | user proxy's class that can be used to replace the default user proxy.<br/><br/>**Type:** `autogen.ConversableAgent \| None`<br/><br/>**Default:** None |
| `max_agents` | **Type:** `int \| None`<br/><br/>**Default:** None |
| `**kwargs` |  |

<b>Returns:</b>
| Type | Description |
|--|--|
| `tuple[list[autogen.ConversableAgent], dict]` | agent_list: a list of agents. cached_configs: cached configs. |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### build_from_library

```python
build_from_library(
    self,
    building_task: str,
    library_path_or_json: str,
    default_llm_config: dict,
    top_k: int = 3,
    coding: bool | None = None,
    code_execution_config: dict | None = None,
    use_oai_assistant: bool | None = False,
    embedding_model: str | None = 'all-mpnet-base-v2',
    user_proxy: autogen.ConversableAgent | None = None,
    **kwargs
) -> tuple[list[autogen.ConversableAgent], dict]
```

    Build agents from a library.
    The library is a list of agent configs, which contains the name and system_message for each agent.
    We use a build manager to decide what agent in that library should be involved to the task.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `building_task` | instruction that helps build manager (gpt-4) to decide what agent should be built.<br/><br/>**Type:** `str` |
| `library_path_or_json` | path or JSON string config of agent library.<br/><br/>**Type:** `str` |
| `default_llm_config` | specific configs for LLM (e.g., config_list, seed, temperature, ...).<br/><br/>**Type:** `dict` |
| `top_k` | **Type:** `int`<br/><br/>**Default:** 3 |
| `coding` | use to identify if the user proxy (a code interpreter) should be added.<br/><br/>**Type:** `bool \| None`<br/><br/>**Default:** None |
| `code_execution_config` | specific configs for user proxy (e.g., last_n_messages, work_dir, ...).<br/><br/>**Type:** `dict \| None`<br/><br/>**Default:** None |
| `use_oai_assistant` | use OpenAI assistant api instead of self-constructed agent.<br/><br/>**Type:** `bool \| None`<br/><br/>**Default:** False |
| `embedding_model` | a Sentence-Transformers model use for embedding similarity to select agents from library.<br/><br/>As reference, chromadb use "all-mpnet-base-v2" as default.<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** 'all-mpnet-base-v2' |
| `user_proxy` | user proxy's class that can be used to replace the default user proxy.<br/><br/>**Type:** `autogen.ConversableAgent \| None`<br/><br/>**Default:** None |
| `**kwargs` |  |

<b>Returns:</b>
| Type | Description |
|--|--|
| `tuple[list[autogen.ConversableAgent], dict]` | agent_list: a list of agents. cached_configs: cached configs. |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### clear_agent

```python
clear_agent(
    self,
    agent_name: str,
    recycle_endpoint: bool | None = True
) -> 
```

    Clear a specific agent by name.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `agent_name` | the name of agent.<br/><br/>**Type:** `str` |
| `recycle_endpoint` | trigger for recycle the endpoint server.<br/><br/>If true, the endpoint will be recycled when there is no agent depending on.<br/><br/>**Type:** `bool \| None`<br/><br/>**Default:** True |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### clear_all_agents

```python
clear_all_agents(self, recycle_endpoint: bool | None = True) -> 
```

    Clear all cached agents.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `recycle_endpoint` | **Type:** `bool \| None`<br/><br/>**Default:** True |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### load

```python
load(
    self,
    filepath: str | None = None,
    config_json: str | None = None,
    use_oai_assistant: bool | None = False,
    **kwargs
) -> tuple[list[autogen.ConversableAgent], dict]
```

    Load building configs and call the build function to complete building without calling online LLMs' api.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `filepath` | filepath or JSON string for the save config.<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** None |
| `config_json` | JSON string for the save config.<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** None |
| `use_oai_assistant` | use OpenAI assistant api instead of self-constructed agent.<br/><br/>**Type:** `bool \| None`<br/><br/>**Default:** False |
| `**kwargs` |  |

<b>Returns:</b>
| Type | Description |
|--|--|
| `tuple[list[autogen.ConversableAgent], dict]` | agent_list: a list of agents. cached_configs: cached configs. |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### save

```python
save(self, filepath: str | None = None) -> str
```

    Save building configs. If the filepath is not specific, this function will create a filename by encrypt the
    building_task string by md5 with "save_config_" prefix, and save config to the local path.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `filepath` | save path.<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** None |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### set_agent_model

```python
set_agent_model(self, model: str) -> 
```

    

<b>Parameters:</b>
| Name | Description |
|--|--|
| `model` | **Type:** `str` |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### set_builder_model

```python
set_builder_model(self, model: str) -> 
```

    

<b>Parameters:</b>
| Name | Description |
|--|--|
| `model` | **Type:** `str` |

<br />