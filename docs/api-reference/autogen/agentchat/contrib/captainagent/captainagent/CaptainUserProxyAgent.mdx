---
sidebarTitle: CaptainUserProxyAgent
title: autogen.agentchat.contrib.captainagent.captainagent.CaptainUserProxyAgent
---
<h2 id="autogen.agentchat.contrib.captainagent.captainagent.CaptainUserProxyAgent" class="doc doc-heading">
    <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>
    <span class="doc doc-object-name doc-class-name">CaptainUserProxyAgent</span>
</h2>

```python
CaptainUserProxyAgent(
    name: str,
    nested_config: dict,
    agent_config_save_path: str = None,
    is_termination_msg: Callable[[dict], bool] | None = None,
    max_consecutive_auto_reply: int | None = None,
    human_input_mode: str | None = 'NEVER',
    code_execution_config: dict | Literal[False] | None = None,
    default_auto_reply: dict | str | None = "I'm a proxy and I can only execute your tool or end the conversation. If you think the problem is solved, please reply me only with 'TERMINATE'.",
    llm_config: dict | Literal[False] | None = False,
    system_message: str | list | None = '',
    description: str | None = None
)
```

    (In preview) A proxy agent for the captain agent, that can execute code and provide feedback to the other agents.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `name` | name of the agent.<br/><br/>**Type:** `str` |
| `nested_config` | the configuration for the nested chat instantiated by CaptainAgent.<br/><br/>**Type:** `dict` |
| `agent_config_save_path` | **Type:** `str`<br/><br/>**Default:** None |
| `is_termination_msg` | a function that takes a message in the form of a dictionary and returns a boolean value indicating if this received message is a termination message.<br/><br/>The dict can contain the following keys: "content", "role", "name", "function_call".<br/><br/>**Type:** `Callable[[dict], bool] \| None`<br/><br/>**Default:** None |
| `max_consecutive_auto_reply` | the maximum number of consecutive auto replies.<br/><br/>default to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).<br/><br/>The limit only plays a role when human_input_mode is not "ALWAYS".<br/><br/>**Type:** `int \| None`<br/><br/>**Default:** None |
| `human_input_mode` | whether to ask for human inputs every time a message is received.<br/><br/>Possible values are "ALWAYS", "TERMINATE", "NEVER".<br/><br/>(1) When "ALWAYS", the agent prompts for human input every time a message is received.<br/><br/>Under this mode, the conversation stops when the human input is "exit", or when is_termination_msg is True and there is no human input.<br/><br/>(2) When "TERMINATE", the agent only prompts for human input only when a termination message is received or the number of auto reply reaches the max_consecutive_auto_reply.<br/><br/>(3) When "NEVER", the agent will never prompt for human input.<br/><br/>Under this mode, the conversation stops when the number of auto reply reaches the max_consecutive_auto_reply or when is_termination_msg is True.<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** 'NEVER' |
| `code_execution_config` | config for the code execution.<br/><br/>To disable code execution, set to False.<br/><br/>Otherwise, set to a dictionary with the following keys: - work_dir (Optional, str): The working directory for the code execution.<br/><br/>If None, a default working directory will be used.<br/><br/>The default working directory is the "extensions" directory under "path_to_autogen".<br/><br/>- use_docker (Optional, list, str or bool): The docker image to use for code execution.<br/><br/>Default is True, which means the code will be executed in a docker container.<br/><br/>A default list of images will be used.<br/><br/>If a list or a str of image name(s) is provided, the code will be executed in a docker container with the first image successfully pulled.<br/><br/>If False, the code will be executed in the current environment.<br/><br/>We strongly recommend using docker for code execution.<br/><br/>- timeout (Optional, int): The maximum execution time in seconds.<br/><br/>- last_n_messages (Experimental, Optional, int): The number of messages to look back for code execution.<br/><br/>Default to 1.<br/><br/>**Type:** `dict \| Literal[False] \| None`<br/><br/>**Default:** None |
| `default_auto_reply` | the default auto reply message when no code execution or llm based reply is generated.<br/><br/>**Type:** `dict \| str \| None`<br/><br/>**Default:** "I'm a proxy and I can only execute your tool or end the conversation. If you think the problem is solved, please reply me only with 'TERMINATE'." |
| `llm_config` | llm inference configuration.<br/><br/>Please refer to [OpenAIWrapper.create](/reference/autogen/OpenAIWrapper#create) for available options.<br/><br/>Default to false, which disables llm-based auto reply.<br/><br/>**Type:** `dict \| Literal[False] \| None`<br/><br/>**Default:** False |
| `system_message` | system message for ChatCompletion inference.<br/><br/>Only used when llm_config is not False.<br/><br/>Use it to reprogram the agent.<br/><br/>**Type:** `str \| list \| None`<br/><br/>**Default:** '' |
| `description` | a short description of the agent.<br/><br/>This description is used by other agents (e.g.<br/><br/>the GroupChatManager) to decide when to call upon this agent.<br/><br/>(Default: system_message)<br/><br/>**Type:** `str \| None`<br/><br/>**Default:** None |

### Class Attributes

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### AUTOBUILD_TASK_DESC
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### CONVERSATION_REVIEW_PROMPT
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### DEFAULT_AUTO_REPLY
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### DEFAULT_USER_PROXY_AGENT_DESCRIPTIONS
<br />

    <br />