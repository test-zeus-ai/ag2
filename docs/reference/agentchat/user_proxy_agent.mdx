---
sidebarTitle: user_proxy_agent
title: agentchat.user_proxy_agent
---

## UserProxyAgent

```python
class UserProxyAgent(ConversableAgent)
```

(In preview) A proxy agent for the user, that can execute code and provide feedback to the other agents.

UserProxyAgent is a subclass of ConversableAgent configured with `human_input_mode` to ALWAYS
and `llm_config` to False. By default, the agent will prompt for human input every time a message is received.
Code execution is enabled by default. LLM-based auto reply is disabled by default.
To modify auto reply, register a method with [`register_reply`](conversable_agent#register-reply).
To modify the way to get human input, override `get_human_input` method.
To modify the way to execute code blocks, single code block, or function call, override `execute_code_blocks`,
`run_code`, and `execute_function` methods respectively.

### \_\_init\_\_

```python
def __init__(name: str,
             is_termination_msg: Optional[Callable[[dict], bool]] = None,
             max_consecutive_auto_reply: Optional[int] = None,
             human_input_mode: Literal["ALWAYS", "TERMINATE",
                                       "NEVER"] = "ALWAYS",
             function_map: Optional[dict[str, Callable]] = None,
             code_execution_config: Union[dict, Literal[False]] = {},
             default_auto_reply: Optional[Union[str, dict, None]] = "",
             llm_config: Optional[Union[dict, Literal[False]]] = False,
             system_message: Optional[Union[str, list]] = "",
             description: Optional[str] = None,
             **kwargs)
```

**Arguments**:

- `name` _str_ - name of the agent.
- `is_termination_msg` _function_ - a function that takes a message in the form of a dictionary
  and returns a boolean value indicating if this received message is a termination message.
  The dict can contain the following keys: "content", "role", "name", "function_call".
- `max_consecutive_auto_reply` _int_ - the maximum number of consecutive auto replies.
  default to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).
  The limit only plays a role when human_input_mode is not "ALWAYS".
- `human_input_mode` _str_ - whether to ask for human inputs every time a message is received.
  Possible values are "ALWAYS", "TERMINATE", "NEVER".
  (1) When "ALWAYS", the agent prompts for human input every time a message is received.
  Under this mode, the conversation stops when the human input is "exit",
  or when is_termination_msg is True and there is no human input.
  (2) When "TERMINATE", the agent only prompts for human input only when a termination message is received or
  the number of auto reply reaches the max_consecutive_auto_reply.
  (3) When "NEVER", the agent will never prompt for human input. Under this mode, the conversation stops
  when the number of auto reply reaches the max_consecutive_auto_reply or when is_termination_msg is True.
- `function_map` _dict[str, callable]_ - Mapping function names (passed to openai) to callable functions.
- `code_execution_config` _dict or False_ - config for the code execution.
  To disable code execution, set to False. Otherwise, set to a dictionary with the following keys:
  - work_dir (Optional, str): The working directory for the code execution.
  If None, a default working directory will be used.
  The default working directory is the "extensions" directory under
  "path_to_autogen".
  - use_docker (Optional, list, str or bool): The docker image to use for code execution.
  Default is True, which means the code will be executed in a docker container. A default list of images will be used.
  If a list or a str of image name(s) is provided, the code will be executed in a docker container
  with the first image successfully pulled.
  If False, the code will be executed in the current environment.
  We strongly recommend using docker for code execution.
  - timeout (Optional, int): The maximum execution time in seconds.
  - last_n_messages (Experimental, Optional, int): The number of messages to look back for code execution. Default to 1.
- `default_auto_reply` _str or dict or None_ - the default auto reply message when no code execution or llm based reply is generated.
- `llm_config` _dict or False or None_ - llm inference configuration.
  Please refer to [OpenAIWrapper.create](/docs/reference/oai/client#create)
  for available options.
  Default to False, which disables llm-based auto reply.
  When set to None, will use self.DEFAULT_CONFIG, which defaults to False.
- `system_message` _str or List_ - system message for ChatCompletion inference.
  Only used when llm_config is not False. Use it to reprogram the agent.
- `description` _str_ - a short description of the agent. This description is used by other agents
  (e.g. the GroupChatManager) to decide when to call upon this agent. (Default: system_message)
- `**kwargs` _dict_ - Please refer to other kwargs in
  [ConversableAgent](conversable_agent#init).

